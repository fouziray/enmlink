{
  "throughput.throughput_dyn": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 3,
    "confused_with": {
      "throughput.throughput_DL": 1,
      "time": 1
    }
  },
  "Sector": {
    "precision": 0.8378378378378378,
    "recall": 0.8378378378378378,
    "f1-score": 0.8378378378378378,
    "support": 37,
    "confused_with": {}
  },
  "throughput.throughput_ca": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 10,
    "confused_with": {
      "throughput": 2,
      "throughput.throughput_DL": 1
    }
  },
  "Tech4g": {
    "precision": 0.9166666666666666,
    "recall": 0.8148148148148148,
    "f1-score": 0.8627450980392156,
    "support": 27,
    "confused_with": {
      "Tech3g": 4
    }
  },
  "Tech2g": {
    "precision": 1.0,
    "recall": 0.6190476190476191,
    "f1-score": 0.7647058823529412,
    "support": 21,
    "confused_with": {
      "code_site": 1
    }
  },
  "throughput.throughput_UL": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 3,
    "confused_with": {
      "throughput": 1
    }
  },
  "Person": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 5,
    "confused_with": {}
  },
  "Tech3g": {
    "precision": 0.5833333333333334,
    "recall": 0.4117647058823529,
    "f1-score": 0.4827586206896552,
    "support": 17,
    "confused_with": {
      "code_site": 1
    }
  },
  "time": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 4,
    "confused_with": {
      "throughput.throughput_DL": 2,
      "code_site": 1,
      "Tech4g": 1
    }
  },
  "code_site": {
    "precision": 0.85,
    "recall": 0.8947368421052632,
    "f1-score": 0.8717948717948718,
    "support": 19,
    "confused_with": {}
  },
  "throughput.throughput_DL": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 14,
    "confused_with": {
      "time": 4,
      "time.throughput_dyn": 1
    }
  },
  "conditions": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 3,
    "confused_with": {}
  },
  "micro avg": {
    "precision": 0.7692307692307693,
    "recall": 0.5521472392638037,
    "f1-score": 0.6428571428571429,
    "support": 163
  },
  "macro avg": {
    "precision": 0.34898648648648645,
    "recall": 0.29818348497399066,
    "f1-score": 0.31832019255954347,
    "support": 163
  },
  "weighted avg": {
    "precision": 0.6307770961145194,
    "recall": 0.5521472392638037,
    "f1-score": 0.583582455780965,
    "support": 163
  },
  "accuracy": 0.9337589784517158
}